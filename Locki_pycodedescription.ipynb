{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/locki-io/pycode-desc/blob/main/Locki_pycodedescription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_XJcxqx22uj"
      },
      "source": [
        "# Using Locki Descriptor to have your code interacting with AI.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First you need to load your file here"
      ],
      "metadata": {
        "id": "oc006Yt9VvXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the custom Python file\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "qovL5JOfVjAp",
        "outputId": "0ecb552f-e074-4da5-f64b-d09006d05052"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-06dcff8e-f258-4879-a732-3084bfe4d2e8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-06dcff8e-f258-4879-a732-3084bfe4d2e8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving stream_calin_1.py to stream_calin_1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let us install OpenAI and Gradio"
      ],
      "metadata": {
        "id": "b4yxtyx8YUdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install -q gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTS_33LZYZtC",
        "outputId": "3c5c4e0c-efb8-4111-f867-6bcb75aa0d10"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure OpenAI Connection"
      ],
      "metadata": {
        "id": "E-Nl2fEcmCBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# Use getpass to input the API key without displaying it\n",
        "api_key = getpass.getpass('Enter your OpenAI API Key: ')\n",
        "\n",
        "# Set the API key\n",
        "openai.api_key = api_key\n",
        "\n",
        "# Set the API key as an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFjqww5tY-kt",
        "outputId": "0e48a925-8d77-4844-b3db-62b29db5dae5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let us prepare the gradio prompt"
      ],
      "metadata": {
        "id": "X4R_dAxSWIcO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qtlFLbke2Sob"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "\n",
        "\n",
        "class Chat:\n",
        "\n",
        "    def __init__(self, system: Optional[str] = None):\n",
        "        self.system = system\n",
        "        self.messages = []\n",
        "\n",
        "        if system is not None:\n",
        "            self.messages.append({\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system\n",
        "            })\n",
        "\n",
        "    def prompt(self, content: str) -> str:\n",
        "          self.messages.append({\n",
        "              \"role\": \"user\",\n",
        "              \"content\": content\n",
        "          })\n",
        "          response = openai.ChatCompletion.create(\n",
        "              model=\"gpt-3.5-turbo\",\n",
        "              messages=self.messages\n",
        "          )\n",
        "          response_content = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "          self.messages.append({\n",
        "              \"role\": \"assistant\",\n",
        "              \"content\": response_content\n",
        "          })\n",
        "          return response_content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R06dbZZaYJDq"
      },
      "source": [
        "## Now we'll wrap this function with a Gradio interface."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "# Get the API key from the environment variable\n",
        "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "myprompt = \"You are a Blender script interpreter. \" \\\n",
        "            \"Please describe the artistic and functional aspects \" \\\n",
        "            \"of the following Python code. \" \\\n",
        "            \"Provide an originality index by comparing it \" \\\n",
        "            \"to existing Blender Python code at the end.\"\n",
        "\n",
        "# Create a variable to store the uploaded Python script content\n",
        "uploaded_script_content = \"\"\n",
        "\n",
        "def respond(uploaded):\n",
        "\n",
        "    # Set the API key for this function\n",
        "    openai.api_key = api_key\n",
        "\n",
        "    message_with_code = f\"{myprompt}\\n\\n{uploaded}\"\n",
        "\n",
        "    # Create a message for the OpenAI API\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful python code assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": message_with_code}\n",
        "    ]\n",
        "\n",
        "    # Call the OpenAI API\n",
        "    response = openai.Completion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        max_tokens=1000\n",
        "    )\n",
        "\n",
        "    return response.choices[0].text\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=respond,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Upload Python Script\", value=uploaded),\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Locki Bot Response powered by ChatGPT3.5\"),\n",
        "    live=False,  # Set live to False to disable automatic updates\n",
        "    title=\"Blender Script Interpreter\",\n",
        "    description=\"Locki uses a specific prompt to describe python code used in Blender.\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True, share=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sj4RgBRhkLc6",
        "outputId": "03cae1f5-a8ad-4da8-efd1-64f38b1c03da"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-4a8065a24420>:43: GradioUnusedKwargWarning: You have unused kwarg parameters in Button, please remove them: {'type': 'button', 'onclick': True}\n",
            "  gr.Button(label=\"Process Script\", type=\"button\", onclick=True)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:810: UserWarning: Expected 1 arguments for function <function respond at 0x7c3b489bd3f0>, received 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:818: UserWarning: Expected maximum 1 arguments for function <function respond at 0x7c3b489bd3f0>, received 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://bb46f325a88915ad17.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bb46f325a88915ad17.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/routes.py\", line 534, in predict\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 226, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1554, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1192, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 659, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "TypeError: respond() takes 1 positional argument but 2 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://bb46f325a88915ad17.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio\n",
        "print(gradio.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpI3pTfjhbIS",
        "outputId": "84aab5a3-fe66-48e2-8dea-862c4b03a2a8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.47.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TESTING OPENAI directly"
      ],
      "metadata": {
        "id": "huohXY3qmKgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Set the API key\n",
        "openai.api_key = api_key\n",
        "\n",
        "prompt = 'You are a Blender script interpreter. Please describe the artistic and functional aspects of the following Python code. Provide an originality index by comparing it to existing Blender Python code at the end. '\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful python code assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"{prompt}\\n{uploaded}\"}\n",
        "    ]\n",
        ")\n",
        "# Get the AI's response\n",
        "ai_response = response['choices'][0]['message']['content']\n",
        "print(ai_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwJcTtKkYb6Q",
        "outputId": "22a1e74c-cefa-431a-f81f-4f4c198dded0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The code provided is a Blender script that creates a visually appealing animation by generating and animating multiple icosahedrons in 3D space. Additionally, it creates three torus objects that surround the icosahedron structure, and animates their rotation and color change. The animation is set to loop.\n",
            "\n",
            "Here is a breakdown of the code's artistic and functional aspects:\n",
            "\n",
            "Artistic aspects:\n",
            "- The code uses the icosahedron and torus shapes, which are geometrically interesting and visually appealing.\n",
            "- The animation creates a wave-like motion for the icosahedrons, giving them a dynamic appearance.\n",
            "- Each icosahedron is assigned a unique material and their color changes over time, creating a visually striking effect.\n",
            "- The torus objects rotate and change color along with the icosahedrons, adding complexity and visual interest to the animation.\n",
            "\n",
            "Functional aspects:\n",
            "- The code clears any existing mesh objects before generating the new ones, ensuring a clean starting point.\n",
            "- The parameters for the number of icosahedrons, columns, planes, distance between them, and total frames are customizable.\n",
            "- The script makes use of the built-in Blender functions to create and manipulate objects, apply modifiers, create materials, and set keyframes for animation.\n",
            "- The animation is set to loop and can be adjusted by changing the start and end frames.\n",
            "- The code includes comments to explain the purpose of each section and variable.\n",
            "\n",
            "Originality index:\n",
            "Since this is a specific script for Blender, it is difficult to find exact duplicates. However, the code combines different elements such as icosahedrons, torus objects, animation, and color change to create a unique visual effect. While there may be similar scripts that use similar concepts, the combination of these elements and the specific implementation of the animation make it reasonably original.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQheRaw5YVTL"
      },
      "source": [
        "That's all! Go ahead and open that share link in a new tab. Check out our [getting started](https://gradio.app/getting_started.html) page for more complicated demos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}